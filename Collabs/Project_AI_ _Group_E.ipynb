{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "didD6aN8Yq8_"
      },
      "source": [
        "# Import Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRJKFX4_-gu1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "import matplotlib.pyplot as plt # used to plot the model graph \n",
        "import numpy as np # used for math calculations\n",
        "import os \n",
        "from glob import glob # used to get all the files in a directory\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import * # used for image manipulation\n",
        "\n",
        "#for loading and visualizing audio files\n",
        "import librosa #import librosa\n",
        "import librosa as lr\n",
        "import librosa.display # display audio files\n",
        "\n",
        "from random import shuffle # for shuffling the data\n",
        "\n",
        "from pathlib import Path\n",
        "import pathlib\n",
        "import wave\n",
        "import contextlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqmFD2DC_3gL",
        "outputId": "e44984f3-5e97-4556-be48-7fd44455177d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-927cf6731897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m \u001b[0;31m# Used to access Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 124\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive # Used to access Google Drive\n",
        "drive.mount('/content/drive') # Mount Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTRIGsoQYGTO"
      },
      "source": [
        "Downloading the samples from the teacher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3VZ0OKI-qXU"
      },
      "outputs": [],
      "source": [
        "!cd test_sample/wavFile/ && wget https://alg.backprop.fr/data4colab/sounds/en_01.wav \n",
        "!cd test_sample/wavFile/ && wget https://alg.backprop.fr/data4colab/sounds/fr_01.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6p-rD1TY2TG"
      },
      "source": [
        "# Getting the prepared spectrograms from the drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3dnQQF6AHmn"
      },
      "outputs": [],
      "source": [
        "##Getting the spectrograms from the drive\n",
        "%%shell \n",
        "cp ./drive/MyDrive/Spectrograms/train.zip /content/ # copy the train.zip file to the folder\n",
        "cp ./drive/MyDrive/Spectrograms/test.zip /content/ # copy the test.zip file to the folder\n",
        "\n",
        "unzip -q '/content/train.zip' -d '/content/' && rm /content/train.zip  # unzip the train.zip file to the folder and remove the zip file\n",
        "unzip -q '/content/test.zip' -d '/content/' && rm /content/test.zip  # unzip the test.zip file to the folder and remove the zip file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLwd6xF6Y7O-"
      },
      "source": [
        "# Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftPqVQRF_LvQ"
      },
      "outputs": [],
      "source": [
        "img_width, img_height = 500, 128 # Setting the image size\n",
        "batch_size = 32                  # batch size\n",
        "epochs = 50                      # number of epochs\n",
        "validation_split = 0.2           # validation split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIsDIwdCLVIX"
      },
      "outputs": [],
      "source": [
        "all_files = glob('train/*/*.png') # Getting all the spectrograms from the train folder\n",
        "\n",
        "num_validation = len(all_files) * validation_split # Defining the number of validation files\n",
        "num_train = len(all_files) - num_validation # Define the number of training images\n",
        "\n",
        "validation_steps = int(num_validation / batch_size) # Calculating the number of steps for the validation\n",
        "steps_per_epoch = int(num_train / batch_size) # Calculating the number of steps for the training\n",
        "\n",
        "print('Steps per Epoch: ' + str(steps_per_epoch)) \n",
        "print('Validation steps: ' + str(validation_steps))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_31zkPZnY9r0"
      },
      "source": [
        "# Train and Test definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgAN5oF3A3DL"
      },
      "outputs": [],
      "source": [
        "image_data_generator = ImageDataGenerator(validation_split=validation_split,rescale=1./255) # rescale to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4H6PGBE_QL5"
      },
      "outputs": [],
      "source": [
        "train_data_generator = image_data_generator.flow_from_directory( # train_data_generator\n",
        "    './train/',\n",
        "    target_size=(img_width, img_height), \n",
        "    batch_size=batch_size, \n",
        "    class_mode='binary', \n",
        "    subset='training',\n",
        "    color_mode = 'grayscale')\n",
        "\n",
        "validation_generator = image_data_generator.flow_from_directory( # validation_generator\n",
        "    './train/',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    color_mode='grayscale')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8dPXngfAVfe"
      },
      "outputs": [],
      "source": [
        "test_data_generator = image_data_generator.flow_from_directory( # test_data_generator\n",
        "    './test/',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    color_mode='grayscale')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B8HboLUZATL"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQTFijUHZd3m"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdVdDyq7BWTZ"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.GlobalMaxPool2D(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DquBr9mHQCc_"
      },
      "outputs": [],
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',    # val_accuracy\n",
        "    patience=8,                # patience before stop the train\n",
        "    verbose=1,                 # verbose\n",
        "    mode='max',                # mode\n",
        "    restore_best_weights=True  # restore best weights\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRu5yWQzBfSl"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ3OcvQKBicG"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqRUuB9cLmzu"
      },
      "outputs": [],
      "source": [
        "model.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PgULNVmZEZ8"
      },
      "source": [
        "# Fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMELQiTAfRD7"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_data_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LgCsx6WBrl8"
      },
      "outputs": [],
      "source": [
        "_, accuracy = model.evaluate(test_data_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikN9HOPeJpe_"
      },
      "outputs": [],
      "source": [
        "print('Accuracy of the model: ' + str(round(accuracy * 100., 1)) + '%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsbs5gkEZHDU"
      },
      "source": [
        "# Plotting values from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1FGHvT0CjbB"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy for '+ str(epochs)+' epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train', 'validation'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyLdHnmCZKfb"
      },
      "source": [
        "# Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWBp_6sXhCEc"
      },
      "outputs": [],
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('saved_model/model_'+ str(round(accuracy * 100.))+'_accuracy', save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZzBOarBYpy0"
      },
      "outputs": [],
      "source": [
        "!mkdir .testingWav\n",
        "!cp ./drive/MyDrive/EN/TestSample/*.wav ./testingWav/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "939AIkUUZNUs"
      },
      "source": [
        "# Make prediction from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPd26mzARw-1"
      },
      "outputs": [],
      "source": [
        "global_files = glob(\"./*/*/*.png\") # get all files frrom the training folder and test folder\n",
        "shuffle(global_files) # shuffle the dataset to randomize \n",
        "random_file = global_files[0] # choose a random file from all the dataset\n",
        "print(random_file)\n",
        "\n",
        "\n",
        "img = tf.keras.utils.load_img((random_file), target_size=(500, 128),color_mode='grayscale') # load the image\n",
        "img_array = tf.keras.utils.img_to_array(img)/255 # convert the image to an array\n",
        "img_array = tf.expand_dims(img_array,0) # add a dimension to the array\n",
        "\n",
        "predict = model.predict(img_array) # Make a prediction on the random image\n",
        "label = predict[0][0] # Get the value of the prediction\n",
        "\n",
        "# More is close to 0, more the prediction is an English conversation\n",
        "# Less is close to 1, more the prediction is a French conversation\n",
        "print('Value: ' + str(label)) \n",
        "\n",
        "if(label <= 0.25): \n",
        "  print(\"You're speaking mostly in English\")\n",
        "elif(label > 0.75): \n",
        "  print(\"You're speaking mostly in French\") \n",
        "elif(label > 0.25 and label <= 0.50): \n",
        "  print(\"It's look like you're speaking in English\")\n",
        "elif(label > 0.50 and label <= 0.75): \n",
        "  print(\"It's look like you're speaking in French\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvVo0VDJaxZs"
      },
      "source": [
        "# Other functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujfiI_sTbe2u"
      },
      "outputs": [],
      "source": [
        "!mkdir saved_model\n",
        "!cp ./drive/MyDrive/Models/*.h5 ./saved_model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeFz9N6xjPvL"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ./test_sample/wavFile/ ./test_sample/pngFile/\n",
        "!cp ./drive/MyDrive/EN/TestSample/*.wav ./test_sample/wavFile/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW-7ohircM7F"
      },
      "outputs": [],
      "source": [
        "def getResult(label):\n",
        "  if(label <= 0.25): \n",
        "    percentage = 100 - (label * 100)\n",
        "    result = 'You\\'re speaking mostly in English at ' + str(round(percentage, 3)) +'%'\n",
        "  elif(label > 0.75): \n",
        "    percentage = label * 100\n",
        "    result = 'You\\'re speaking mostly in French at ' + str(round(percentage, 3)) +'%'\n",
        "  elif(label > 0.25 and label <= 0.50):\n",
        "    percentage = 100 - (label * 100)\n",
        "    result = 'It\\'s look like you\\'re speaking in English at '  + str(round(percentage, 3)) +'%'\n",
        "  elif(label > 0.50 and label <= 0.75):\n",
        "    percentage = label * 100\n",
        "    result = 'It\\'s look like you\\'re speaking in French at ' + str(round(percentage, 3)) +'%'\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj7jRrkwhzPW"
      },
      "outputs": [],
      "source": [
        "def createSpectrogram(audio_segment):\n",
        "    \n",
        "    h1 = audio_segment.shape[0] // img_width\n",
        "    spec = lr.feature.melspectrogram(audio_segment, n_mels=img_height, hop_length=int(h1))\n",
        "\n",
        "    image = lr.core.power_to_db(spec)\n",
        "\n",
        "    image_np = np.asmatrix(image)\n",
        "\n",
        "    image_np_scaled_temp = (image_np - np.min(image_np))\n",
        "\n",
        "    image_np_scaled = image_np_scaled_temp / np.max(image_np_scaled_temp)\n",
        "\n",
        "    return image_np_scaled[:, 0:img_width]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qQR31QDifw7"
      },
      "outputs": [],
      "source": [
        "def makeSpectrogramOfFolder(path_folder):\n",
        "  # Define Global variables\n",
        "\n",
        "  directorySample = path_folder\n",
        "  outputSample = \"./test_sample/pngFile/\"\n",
        "\n",
        "  directories = [directorySample]\n",
        "  outputs = [outputSample]\n",
        "\n",
        "  for directory in directories:\n",
        "    for filename in os.listdir(directory):\n",
        "      filetitle, _ = os.path.splitext(filename)\n",
        "      audio_segment, sample_rate = librosa.load(directory+filename)\n",
        "      a = createSpectrogram(audio_segment)\n",
        "      for i in range(0,len(outputs)):\n",
        "        if directory == directories[i]:\n",
        "          plt.imsave(outputs[i]+filetitle+\".png\", a, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghi7G2DKk8g8"
      },
      "outputs": [],
      "source": [
        "def makeSpectrogramOfFile(file_path):\n",
        "  # Define Global variables\n",
        "  filename = './test_sample/wavFile/en_sample_n3.wav'\n",
        "  output = \"./test_sample/pngFile/\"\n",
        "\n",
        "  filetitle = Path(file_path).stem\n",
        "  audio_segment, sample_rate = librosa.load(file_path)\n",
        "  a = createSpectrogram(audio_segment)\n",
        "  path = plt.imsave(output+filetitle+\".png\", a, cmap='gray')\n",
        "\n",
        "  png_path = output+filetitle+\".png\"\n",
        "  return png_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYgaqkXCZvtM"
      },
      "outputs": [],
      "source": [
        "def predictRandomImg(path_model):\n",
        "  loaded_model = tf.keras.models.load_model(path_model)\n",
        "  \n",
        "  global_files = glob(\"./*/*/*.png\") # get all files from the training folder and test folder\n",
        "  shuffle(global_files) # shuffle the dataset to randomize \n",
        "  random_file = global_files[0] # choose a random file from all the dataset\n",
        "\n",
        "  img = tf.keras.utils.load_img((random_file), target_size=(500, 128),color_mode='grayscale') # load the image\n",
        "  img_array = tf.keras.utils.img_to_array(img)/255 # convert the image to an array\n",
        "  img_array = tf.expand_dims(img_array,0) # add a dimension to the array\n",
        "\n",
        "  predict = loaded_model.predict(img_array) # Make a prediction on the random image\n",
        "  label = predict[0][0] # Get the value of the prediction\n",
        "  \n",
        "  return getResult(label) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsDSJXxdaCgl"
      },
      "outputs": [],
      "source": [
        "def predictSpecificImg(image, path_model):\n",
        "  loaded_model = tf.keras.models.load_model(path_model)\n",
        "\n",
        "  img = tf.keras.utils.load_img((image), target_size=(500, 128),color_mode='grayscale') # load the image\n",
        "  img_array = tf.keras.utils.img_to_array(img)/255 # convert the image to an array\n",
        "  img_array = tf.expand_dims(img_array,0) # add a dimension to the array\n",
        "\n",
        "  predict = loaded_model.predict(img_array) # Make a prediction on the random image\n",
        "  label = predict[0][0] # Get the value of the prediction\n",
        "  return getResult(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zofptKB1aKH1"
      },
      "outputs": [],
      "source": [
        "def predictFromWav(wav_path, path_model):\n",
        " return predictSpecificImg(makeSpectrogramOfFile(wav_path), path_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOb74sVCxT-h"
      },
      "outputs": [],
      "source": [
        "# split a wav file of X seconds into smaller wav files of 8 seconds\n",
        "def split_wavFile(wav_path, seconds):\n",
        "    wav_file = wave.open(wav_path, 'r')     # open the wav file\n",
        "    frames = wav_file.getnframes()          # get the number of frames\n",
        "    rate = wav_file.getframerate()          # get the frame rate\n",
        "    duration = frames / float(rate)         # get the duration\n",
        "\n",
        "    if duration < seconds:\n",
        "        error = 'Cannot split the wav file because it is less than 8 seconds, please choose an another wavFile'\n",
        "        return error\n",
        "\n",
        "    elif duration > seconds:\n",
        "      num_chunks = int(duration / seconds)    # get the number of chunks\n",
        "      filetitle = Path(wav_path).stem        # get the file title    \n",
        "\n",
        "      parent_folder = str(pathlib.Path(wav_path).parent.resolve()) + '/'\n",
        "      folder_name = str(Path(wav_path).stem) + '_Splitted/' \n",
        "      os.mkdir(parent_folder + folder_name)\n",
        "\n",
        "      for i in range(num_chunks):             # iterate over the number of chunks\n",
        "          start = i * seconds * rate          # get the start frame\n",
        "          end = (i + 1) * seconds * rate      # get the end frame\n",
        "          wav_file.setpos(start)              # set the position in the file\n",
        "          frames = wav_file.readframes(int(end - start))          # read the frames\n",
        "          out_file = wave.open(parent_folder + str(folder_name) + str(filetitle) + '_' + str(i) + '.wav', 'w')    # open the output file\n",
        "          out_file.setparams(wav_file.getparams())                # set the output file parameters\n",
        "          out_file.writeframes(frames)        # write the frames to the output file\n",
        "          out_file.close()                    # close the output file\n",
        "      wav_file.close()                        # close the input file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3z7gwTTsxzBx"
      },
      "outputs": [],
      "source": [
        "def getWavLength(wav_path):\n",
        "  with contextlib.closing(wave.open(wav_path,'r')) as f:\n",
        "    frames = f.getnframes()\n",
        "    rate = f.getframerate()\n",
        "    duration = frames / float(rate)\n",
        "    result = round(duration,2)\n",
        "    s = 'File: ' + str(wav_path) + ' |  Length: ' + str(result)\n",
        "    return s + 's'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiiDFzzPb7_j"
      },
      "source": [
        "# Testing the functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKZ16rMSCIPX"
      },
      "source": [
        "Make all the spectrograms of the wavfolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tP4JLVsjj4b"
      },
      "outputs": [],
      "source": [
        "#makeSpectrogramOfFolder('./test_sample/wavFile/en_01_Splitted/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMYny02xCPxJ"
      },
      "source": [
        "Predict a random image from the global dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "til30E8jOBhZ"
      },
      "outputs": [],
      "source": [
        "#predictRandomImg('./saved_model/model_99_accuracy.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NjPa4VeCTSh"
      },
      "source": [
        "Predict a specific image "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsOK-3bPhcVb"
      },
      "outputs": [],
      "source": [
        "#predictSpecificImg('./test_sample/pngFile/yes.png', './saved_model/model_99_accuracy.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80uN34mbCaAw"
      },
      "source": [
        "Predict from a wavFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFkTvTHkkbaL"
      },
      "outputs": [],
      "source": [
        "#predictFromWav('./test_sample/wavFile/en_01_Splitted/en_01_1.wav', './saved_model/model_99_accuracy.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u8rumDIZMA-"
      },
      "source": [
        "Splitting the Wav file if it exceed 8 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq4Z-6MZyMk6"
      },
      "outputs": [],
      "source": [
        "#split_wavFile('./test_sample/wavFile/en_01.wav', 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjMOZAYxZnxB"
      },
      "source": [
        "Getting the length of the wavFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iunRfGwkAOff"
      },
      "outputs": [],
      "source": [
        "#getWavLength('./test_sample/wavFile/en_01.wav')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "oLwd6xF6Y7O-",
        "_31zkPZnY9r0",
        "_B8HboLUZATL",
        "7PgULNVmZEZ8",
        "NyLdHnmCZKfb"
      ],
      "name": "Project AI | Group E",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}